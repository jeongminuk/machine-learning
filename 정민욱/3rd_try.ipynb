{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e02a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Pivot Shape: (100, 43)\n",
      "Extracting Pair Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning Leaders: 100%|██████████| 100/100 [00:03<00:00, 32.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying Significant Pairs...\n",
      "Selected Pairs: 2179\n",
      "Building Regression Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Rows: 2179it [00:05, 378.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Hybrid Model (Linear + XGB)...\n",
      "Fold 1 WMAPE: 0.3608\n",
      "Fold 2 WMAPE: 0.2942\n",
      "Fold 3 WMAPE: 0.1940\n",
      "Fold 4 WMAPE: 0.1692\n",
      "Fold 5 WMAPE: 0.1906\n",
      "Average WMAPE: 0.2418\n",
      "Retraining Hybrid Model on Full Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting Hybrid: 2179it [00:06, 343.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. 라이브러리 임포트 및 설정\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn 관련\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression # (비교용으로 남겨둠)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# XGBoost 관련\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# 경고 무시 (선택사항)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# WMAPE (Weighted Mean Absolute Percentage Error) 정의\n",
    "# -> 실제 판매량 규모를 고려한 오차율 평가 지표\n",
    "def wmape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. 데이터 로드 및 전처리 (Pivot 생성)\n",
    "# =============================================================================\n",
    "print(\"Loading Data...\")\n",
    "train = pd.read_csv(\"dataset/train.csv\")\n",
    "\n",
    "# 월별 집계\n",
    "monthly = (\n",
    "    train\n",
    "    .groupby([\"item_id\", \"year\", \"month\"], as_index=False)[\"value\"]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# 'YYYY-MM' 형태의 컬럼 생성\n",
    "monthly[\"ym\"] = pd.to_datetime(\n",
    "    monthly[\"year\"].astype(str) + \"-\" +\n",
    "    monthly[\"month\"].astype(str).str.zfill(2)\n",
    ")\n",
    "\n",
    "# Pivot Table 생성 (행: item_id, 열: ym, 값: value)\n",
    "pivot = (\n",
    "    monthly\n",
    "    .pivot(index=\"item_id\", columns=\"ym\", values=\"value\")\n",
    "    .fillna(0.0)\n",
    ")\n",
    "\n",
    "print(f\"Pivot Shape: {pivot.shape}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Pair Feature Extraction (아이템 간 관계 추출)\n",
    "# =============================================================================\n",
    "def safe_corr(x, y):\n",
    "    \"\"\"표준편차가 0인 경우(변화 없음) 상관계수 계산 오류 방지\"\"\"\n",
    "    if np.std(x) == 0 or np.std(y) == 0:\n",
    "        return 0.0\n",
    "    return float(np.corrcoef(x, y)[0, 1])\n",
    "\n",
    "def extract_pair_features(pivot, max_lag=6, min_nonzero=12):\n",
    "    items = pivot.index.to_list()\n",
    "    n_months = pivot.shape[1]\n",
    "    rows = []\n",
    "\n",
    "    print(\"Extracting Pair Features...\")\n",
    "    for leader in tqdm(items, desc=\"Scanning Leaders\"):\n",
    "        x = pivot.loc[leader].values.astype(float)\n",
    "        if np.count_nonzero(x) < min_nonzero:\n",
    "            continue\n",
    "\n",
    "        for follower in items:\n",
    "            if leader == follower:\n",
    "                continue\n",
    "\n",
    "            y = pivot.loc[follower].values.astype(float)\n",
    "            if np.count_nonzero(y) < min_nonzero:\n",
    "                continue\n",
    "\n",
    "            corrs = []\n",
    "            best_corr, best_lag = 0.0, 0\n",
    "\n",
    "            # Lag 1 ~ max_lag 까지 상관관계 스캔\n",
    "            for lag in range(1, max_lag + 1):\n",
    "                if n_months <= lag:\n",
    "                    continue\n",
    "                # x(leader)가 lag만큼 앞서고, y(follower)가 뒤따름\n",
    "                c = safe_corr(x[:-lag], y[lag:])\n",
    "                corrs.append(abs(c))\n",
    "                if abs(c) > abs(best_corr):\n",
    "                    best_corr = c\n",
    "                    best_lag = lag\n",
    "\n",
    "            rows.append({\n",
    "                \"leader\": leader,\n",
    "                \"follower\": follower,\n",
    "                \"max_corr\": best_corr,\n",
    "                \"best_lag\": best_lag,\n",
    "                \"mean_abs_corr\": np.mean(corrs),\n",
    "                \"std_abs_corr\": np.std(corrs),\n",
    "                \"nonzero_ratio_a\": np.count_nonzero(x) / len(x),\n",
    "                \"nonzero_ratio_b\": np.count_nonzero(y) / len(y),\n",
    "                \"var_ratio\": np.var(y) / (np.var(x) + 1e-6),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows).dropna()\n",
    "\n",
    "pair_df = extract_pair_features(pivot)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. XGBoost Classifier (유의미한 관계 필터링)\n",
    "# =============================================================================\n",
    "print(\"Classifying Significant Pairs...\")\n",
    "\n",
    "# Pseudo-Labeling: 상관계수가 높고 Lag가 존재하는 것을 '관계 있음(1)'으로 가정\n",
    "pair_df[\"label\"] = (\n",
    "    (pair_df[\"max_corr\"].abs() >= 0.35) &\n",
    "    (pair_df[\"best_lag\"] > 0)\n",
    ").astype(int)\n",
    "\n",
    "clf_features = [\n",
    "    \"max_corr\", \"best_lag\",\n",
    "    \"mean_abs_corr\", \"std_abs_corr\",\n",
    "    \"nonzero_ratio_a\", \"nonzero_ratio_b\",\n",
    "    \"var_ratio\"\n",
    "]\n",
    "\n",
    "X_clf = pair_df[clf_features]\n",
    "y_clf = pair_df[\"label\"]\n",
    "\n",
    "# 분류 모델 학습\n",
    "clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "clf.fit(X_clf, y_clf)\n",
    "\n",
    "# 예측 확률 기반 필터링 (확률 0.6 이상인 쌍만 선택)\n",
    "pair_df[\"comove_prob\"] = clf.predict_proba(X_clf)[:, 1]\n",
    "pairs_ml = (\n",
    "    pair_df[pair_df[\"comove_prob\"] >= 0.6]\n",
    "    .rename(columns={\n",
    "        \"leader\": \"leading_item_id\",\n",
    "        \"follower\": \"following_item_id\"\n",
    "    })[[\"leading_item_id\", \"following_item_id\", \"best_lag\", \"max_corr\"]]\n",
    ")\n",
    "\n",
    "print(f\"Selected Pairs: {len(pairs_ml)}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Feature Engineering (회귀 분석용 데이터 생성)\n",
    "# =============================================================================\n",
    "print(\"Building Regression Dataset...\")\n",
    "\n",
    "# 계절성 인덱스 미리 계산\n",
    "seasonal_table = (\n",
    "    monthly.groupby([\"item_id\", \"month\"])[\"value\"]\n",
    "    .mean()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "def build_training_data_fe(pivot, pairs_ml):\n",
    "    n_months = pivot.shape[1]\n",
    "    \n",
    "    # 월 정보를 얻기 위한 작업\n",
    "    pivot_with_month = pivot.copy()\n",
    "    pivot_with_month.columns = pd.to_datetime(pivot_with_month.columns)\n",
    "    seasonal_index_map = pivot_with_month.groupby(\n",
    "        pivot_with_month.columns.month, axis=1\n",
    "    ).mean()\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for row in tqdm(pairs_ml.itertuples(index=False), desc=\"Generating Rows\"):\n",
    "        leader = row.leading_item_id\n",
    "        follower = row.following_item_id\n",
    "        lag = int(row.best_lag)\n",
    "        corr = float(row.max_corr)\n",
    "\n",
    "        a = pivot.loc[leader].values\n",
    "        b = pivot.loc[follower].values\n",
    "\n",
    "        # Rolling Statistics 계산을 위한 임시 DataFrame\n",
    "        b_df = pd.DataFrame({\"b\": b})\n",
    "        for w in [3, 5, 7, 12]:\n",
    "            b_df[f\"roll_mean_{w}\"] = b_df[\"b\"].rolling(w).mean()\n",
    "        for w in [3, 5, 12]:\n",
    "            b_df[f\"roll_std_{w}\"] = b_df[\"b\"].rolling(w).std()\n",
    "\n",
    "        b_df[\"trend\"] = b_df[\"b\"].diff()\n",
    "        \n",
    "        # 월별 계절성 매핑\n",
    "        month_series = pivot_with_month.columns.month\n",
    "        b_df[\"season_index\"] = [seasonal_index_map.loc[follower, m] for m in month_series]\n",
    "\n",
    "        # 학습 데이터 생성 (t 시점에서 t+1 예측)\n",
    "        for t in range(max(lag, 12), n_months - 1):\n",
    "            rows.append({\n",
    "                \"b_t\": b[t],\n",
    "                \"b_t_1\": b[t-1],\n",
    "                \"a_t_lag\": a[t-lag], # Leader의 과거 값\n",
    "                \"max_corr\": corr,\n",
    "                \"best_lag\": lag,\n",
    "                \"roll_mean_3\": b_df.loc[t,\"roll_mean_3\"],\n",
    "                \"roll_mean_5\": b_df.loc[t,\"roll_mean_5\"],\n",
    "                \"roll_mean_7\": b_df.loc[t,\"roll_mean_7\"],\n",
    "                \"roll_mean_12\": b_df.loc[t,\"roll_mean_12\"],\n",
    "                \"roll_std_3\": b_df.loc[t,\"roll_std_3\"],\n",
    "                \"roll_std_5\": b_df.loc[t,\"roll_std_5\"],\n",
    "                \"roll_std_12\": b_df.loc[t,\"roll_std_12\"],\n",
    "                \"trend\": b_df.loc[t,\"trend\"],\n",
    "                \"season_index\": b_df.loc[t,\"season_index\"],\n",
    "                \"target\": b[t+1], # 정답: 다음 달 판매량\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows).dropna()\n",
    "\n",
    "df_train = build_training_data_fe(pivot, pairs_ml)\n",
    "\n",
    "feature_cols = [\n",
    "    'b_t','b_t_1','a_t_lag','max_corr','best_lag',\n",
    "    'roll_mean_3','roll_mean_5','roll_mean_7','roll_mean_12',\n",
    "    'roll_std_3','roll_std_5','roll_std_12',\n",
    "    'trend','season_index'\n",
    "]\n",
    "\n",
    "X = df_train[feature_cols]\n",
    "y = df_train[\"target\"]\n",
    "\n",
    "# =============================================================================\n",
    "# [개선된 Section 6] Hybrid Model (Linear Trend + XGB Residual)\n",
    "# =============================================================================\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"Training Hybrid Model (Linear + XGB)...\")\n",
    "\n",
    "# 시계열 교차 검증\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 하이퍼파라미터 (Optuna로 찾으면 더 좋음)\n",
    "xgb_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.03,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "    'early_stopping_rounds': 50\n",
    "}\n",
    "\n",
    "fold_scores = []\n",
    "\n",
    "# 최종 학습을 위해 모델 객체 저장 리스트\n",
    "fitted_linears = []\n",
    "fitted_xgbs = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # 1. Log 변환\n",
    "    y_train_log = np.log1p(y_train)\n",
    "    y_val_log = np.log1p(y_val)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Step 1: Linear Model로 추세(Trend) 학습\n",
    "    # -------------------------------------------------------\n",
    "    # Ridge는 과적합을 막는 LinearRegression의 사촌입니다.\n",
    "    linear_model = Ridge(alpha=1.0) \n",
    "    linear_model.fit(X_train, y_train_log)\n",
    "    \n",
    "    # Linear 모델의 예측값 (Trend)\n",
    "    pred_train_trend = linear_model.predict(X_train)\n",
    "    pred_val_trend = linear_model.predict(X_val)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Step 2: 잔차(Residual) 계산 (실제값 - Trend)\n",
    "    # -------------------------------------------------------\n",
    "    y_train_resid = y_train_log - pred_train_trend\n",
    "    y_val_resid = y_val_log - pred_val_trend\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Step 3: XGBoost로 잔차(Residual) 학습 (비선형 패턴)\n",
    "    # -------------------------------------------------------\n",
    "    xgb_model = XGBRegressor(**xgb_params)\n",
    "    \n",
    "    xgb_model.fit(\n",
    "        X_train, y_train_resid,\n",
    "        eval_set=[(X_val, y_val_resid)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Step 4: 최종 예측 (Trend + Residual)\n",
    "    # -------------------------------------------------------\n",
    "    pred_val_resid = xgb_model.predict(X_val)\n",
    "    \n",
    "    # Log 상태에서의 최종 예측\n",
    "    pred_log = pred_val_trend + pred_val_resid\n",
    "    \n",
    "    # 원래 스케일로 복원\n",
    "    pred = np.expm1(pred_log)\n",
    "    pred = np.maximum(0, pred)\n",
    "\n",
    "    score = wmape(y_val, pred)\n",
    "    fold_scores.append(score)\n",
    "    print(f\"Fold {fold+1} WMAPE: {score:.4f}\")\n",
    "\n",
    "print(f\"Average WMAPE: {np.mean(fold_scores):.4f}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# [최종 학습 및 추론] 전체 데이터 재학습\n",
    "# =============================================================================\n",
    "print(\"Retraining Hybrid Model on Full Data...\")\n",
    "\n",
    "# 전체 데이터 준비\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# 1. Linear (Trend)\n",
    "final_linear = Ridge(alpha=1.0)\n",
    "final_linear.fit(X, y_log)\n",
    "trend_pred = final_linear.predict(X)\n",
    "\n",
    "# 2. Residual\n",
    "y_resid = y_log - trend_pred\n",
    "\n",
    "# 3. XGB (Residual) - Early Stopping 끄기\n",
    "final_xgb = XGBRegressor(**xgb_params)\n",
    "final_xgb.early_stopping_rounds = None # 전체 학습시 끔\n",
    "final_xgb.fit(X, y_resid, verbose=False)\n",
    "\n",
    "# 4. 예측 함수 수정 (Hybrid 적용)\n",
    "def predict_next_month_hybrid(pivot, pairs_ml, model_linear, model_xgb):\n",
    "    months = pivot.columns\n",
    "    t = len(months) - 1\n",
    "    preds = []\n",
    "    \n",
    "    pivot_cols = pd.to_datetime(pivot.columns)\n",
    "\n",
    "    for row in tqdm(pairs_ml.itertuples(index=False), desc=\"Forecasting Hybrid\"):\n",
    "        leader = row.leading_item_id\n",
    "        follower = row.following_item_id\n",
    "        lag = int(row.best_lag)\n",
    "        corr = float(row.max_corr)\n",
    "        a = pivot.loc[leader].values\n",
    "        b = pivot.loc[follower].values\n",
    "        if t - lag < 0: continue\n",
    "\n",
    "        b_ts = pd.Series(b)\n",
    "        X_test = pd.DataFrame([{\n",
    "            \"b_t\": b[t], \"b_t_1\": b[t-1], \"a_t_lag\": a[t-lag],\n",
    "            \"max_corr\": corr, \"best_lag\": lag,\n",
    "            \"roll_mean_3\": b_ts.rolling(3).mean().iloc[t],\n",
    "            \"roll_mean_5\": b_ts.rolling(5).mean().iloc[t],\n",
    "            \"roll_mean_7\": b_ts.rolling(7).mean().iloc[t],\n",
    "            \"roll_mean_12\": b_ts.rolling(12).mean().iloc[t],\n",
    "            \"roll_std_3\": b_ts.rolling(3).std().iloc[t],\n",
    "            \"roll_std_5\": b_ts.rolling(5).std().iloc[t],\n",
    "            \"roll_std_12\": b_ts.rolling(12).std().iloc[t],\n",
    "            \"trend\": b[t] - b[t-1],\n",
    "            \"season_index\": seasonal_table.loc[follower, pivot_cols[t].month]\n",
    "        }])[feature_cols]\n",
    "\n",
    "        # 1. Linear 예측\n",
    "        trend = model_linear.predict(X_test)[0]\n",
    "        # 2. XGB 예측\n",
    "        resid = model_xgb.predict(X_test)[0]\n",
    "        \n",
    "        # 합산 및 복원\n",
    "        y_hat = np.expm1(trend + resid)\n",
    "        \n",
    "        preds.append({\n",
    "            \"leading_item_id\": leader,\n",
    "            \"following_item_id\": follower,\n",
    "            \"value\": max(0, int(round(y_hat)))\n",
    "        })\n",
    "    return pd.DataFrame(preds)\n",
    "\n",
    "submission = predict_next_month_hybrid(pivot, pairs_ml, final_linear, final_xgb)\n",
    "submission.to_csv(\"mu_hybrid_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
